{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2ad4df",
   "metadata": {},
   "source": [
    "1.\tHow would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadf451",
   "metadata": {},
   "source": [
    "TensorFlow is an open-source machine learning framework developed by Google, designed for building and training deep neural networks. Its main features include automatic differentiation, GPU/CPU acceleration, distributed computing, and high-level APIs for building models. Other popular deep learning libraries include PyTorch, Keras, and Caffe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd98a0",
   "metadata": {},
   "source": [
    "2.\tIs TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b16333",
   "metadata": {},
   "source": [
    "TensorFlow and NumPy are both libraries that are used in numerical computation, but they serve different purposes. NumPy is a library for scientific computing in Python, providing support for arrays, matrices, and other mathematical functions. TensorFlow is a framework for building and training machine learning models, using data flow graphs to represent mathematical operations.\n",
    "\n",
    "While TensorFlow provides support for some array operations similar to NumPy, it is not a drop-in replacement for NumPy. The main differences between the two include:\n",
    "\n",
    "1. Computational graph: TensorFlow uses a computational graph to represent the operations performed on the data, while NumPy uses immediate execution. This allows TensorFlow to optimize the computation and distribute it across multiple devices.\n",
    "\n",
    "2. GPU support: TensorFlow has built-in support for running computations on GPUs, while NumPy relies on external libraries for this.\n",
    "\n",
    "3. Automatic differentiation: TensorFlow provides automatic differentiation, which makes it easier to calculate gradients and train models, while NumPy requires manual implementation of the gradient calculations.\n",
    "\n",
    "4. Model training: TensorFlow includes tools for training and evaluating machine learning models, while NumPy is primarily focused on array operations and mathematical functions.\n",
    "\n",
    "Other popular Deep Learning libraries include PyTorch, Keras, Theano, and Caffe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f397149",
   "metadata": {},
   "source": [
    "3.\tDo you get the same result with tf.range(10) and tf.constant(np.arange(10))?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392a2c6",
   "metadata": {},
   "source": [
    "Yes, both `tf.range(10)` and `tf.constant(np.arange(10))` will give the same result, which is a tensor representing the numbers 0 through 9. The `tf.range()` function creates a sequence of numbers in a range, while `tf.constant()` creates a constant tensor with the provided values. In this case, the `np.arange(10)` creates a NumPy array containing the numbers 0 through 9, which is then passed to `tf.constant()` to create a tensor with those values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3e883",
   "metadata": {},
   "source": [
    "4.\tCan you name six other data structures available in TensorFlow, beyond regular tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896eca93",
   "metadata": {},
   "source": [
    "Yes, here are six other data structures available in TensorFlow, beyond regular tensors:\n",
    "\n",
    "1. Variables: These are mutable tensors that can hold a value and are typically used to store the parameters of a model.\n",
    "\n",
    "2. Constants: These are immutable tensors that hold a fixed value and cannot be changed during runtime.\n",
    "\n",
    "3. Placeholders: These are tensors that do not have an initial value and are typically used to feed input data into a TensorFlow model.\n",
    "\n",
    "4. Sparse Tensors: These are tensors that store values at specific indices, rather than at every position in the tensor.\n",
    "\n",
    "5. Ragged Tensors: These are tensors with variable-length dimensions, which can be useful for representing irregular or unstructured data.\n",
    "\n",
    "6. TensorArray: This is a data structure for storing a sequence of tensors, where the size of the sequence is not known in advance. It is similar to a list in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db00a0",
   "metadata": {},
   "source": [
    "5.\tA custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d387f03",
   "metadata": {},
   "source": [
    "Defining a custom loss function in TensorFlow using the `keras.losses.Loss` class or a simple function both have their own advantages and use cases. \n",
    "\n",
    "A custom loss function can be defined by writing a function in the following cases:\n",
    "\n",
    "1. If the loss function is a simple mathematical function that can be expressed using the TensorFlow operations.\n",
    "2. If the loss function requires inputs other than the predicted and actual values, such as some global parameters or constants.\n",
    "\n",
    "On the other hand, subclassing the `keras.losses.Loss` class can be beneficial in the following cases:\n",
    "\n",
    "1. If the loss function is complex and requires additional logic and computations beyond simple mathematical operations.\n",
    "2. If the loss function needs to keep some internal state, such as a moving average or some other form of history.\n",
    "3. If the loss function has multiple components that need to be combined, such as regularization terms or class weights.\n",
    "\n",
    "By subclassing the `keras.losses.Loss` class, you can have access to all of its methods and attributes, which can provide additional flexibility and functionality when defining the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82177f",
   "metadata": {},
   "source": [
    "6.\tSimilarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d04a7b",
   "metadata": {},
   "source": [
    "A custom metric can be defined in a function or a subclass of `keras.metrics.Metric`. Here are some scenarios when each option might be appropriate:\n",
    "\n",
    "1. Function: If the metric calculation does not require stateful computations across batches or epochs, a simple function can be used to define a custom metric. For example, if you want to calculate the F1 score for a binary classification problem, you can use a function that takes in the true labels and predicted labels for each batch and computes the F1 score using those values. There is no need to define a stateful object for this scenario.\n",
    "\n",
    "2. Subclass of `keras.metrics.Metric`: If the metric calculation requires stateful computations across batches or epochs, or if you want to track additional metrics like precision, recall, etc., then a subclass of `keras.metrics.Metric` should be used. For example, if you want to track the mean absolute error (MAE) across batches and epochs, you can define a subclass of `keras.metrics.Metric` that updates the running sum of absolute errors and the number of samples seen so far. This object can then be used to calculate the mean absolute error at the end of each epoch. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aca521",
   "metadata": {},
   "source": [
    "7.\tWhen should you create a custom layer versus a custom model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f74a9",
   "metadata": {},
   "source": [
    "A custom metric can be defined in a function or a subclass of `keras.metrics.Metric`. Here are some scenarios when each option might be appropriate:\n",
    "\n",
    "1. Function: If the metric calculation does not require stateful computations across batches or epochs, a simple function can be used to define a custom metric. For example, if you want to calculate the F1 score for a binary classification problem, you can use a function that takes in the true labels and predicted labels for each batch and computes the F1 score using those values. There is no need to define a stateful object for this scenario.\n",
    "\n",
    "2. Subclass of `keras.metrics.Metric`: If the metric calculation requires stateful computations across batches or epochs, or if you want to track additional metrics like precision, recall, etc., then a subclass of `keras.metrics.Metric` should be used. For example, if you want to track the mean absolute error (MAE) across batches and epochs, you can define a subclass of `keras.metrics.Metric` that updates the running sum of absolute errors and the number of samples seen so far. This object can then be used to calculate the mean absolute error at the end of each epoch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27c2c6",
   "metadata": {},
   "source": [
    "8.\tWhat are some use cases that require writing your own custom training loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705eb92",
   "metadata": {},
   "source": [
    "Here are some use cases that require writing your own custom training loop:\n",
    "\n",
    "1. Non-standard architectures: Sometimes, we may need to implement a non-standard architecture that cannot be easily implemented using Keras. In this case, writing a custom training loop can be helpful.\n",
    "\n",
    "2. Non-standard loss or metric functions: If we need to use a custom loss function or metric function that cannot be easily implemented using the built-in functions of Keras, we may need to write our own custom training loop.\n",
    "\n",
    "3. Complex training schemes: In some cases, we may need to implement a complex training scheme that requires a more fine-grained control over the training process. In such cases, writing a custom training loop can be helpful.\n",
    "\n",
    "4. Transfer learning: When using transfer learning, we may need to fine-tune a pre-trained model with a different number of layers or a different learning rate schedule. In this case, writing a custom training loop can be useful.\n",
    "\n",
    "5. Debugging: Writing a custom training loop can help us gain a better understanding of the training process and identify any issues or bugs that may be present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59247ecf",
   "metadata": {},
   "source": [
    "9.\tCan custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ba52d",
   "metadata": {},
   "source": [
    "Custom Keras components can contain arbitrary Python code, but they must be convertible to TF Functions in order to be executed on a TensorFlow graph. The conversion to a TF Function can be done either automatically (via the `@tf.function` decorator) or manually (by wrapping the code in a `tf.function()` call). When a custom component is called by a Keras model or training loop, it will be executed as a TensorFlow graph operation. Therefore, any code that cannot be converted to a TensorFlow graph operation (e.g., Python I/O operations) should be avoided in custom Keras components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41aa66f",
   "metadata": {},
   "source": [
    "10.\tWhat are the main rules to respect if you want a function to be convertible to a TF Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87f7a1",
   "metadata": {},
   "source": [
    "To be convertible to a TF Function, a Python function must follow these rules:\n",
    "\n",
    "1. It must only use TensorFlow operations and functions to build its computation graph.\n",
    "2. It must not modify Python data structures or execute Python code that is not TensorFlow-related during the function call.\n",
    "3. It should avoid using Python control flow statements (e.g., if/else, while, for) when possible. If you need to use control flow, it should be done using TensorFlow operations (e.g., tf.cond(), tf.while_loop()).\n",
    "4. It must not use Python exceptions to handle control flow (e.g., raising an exception to exit a loop).\n",
    "5. It must avoid creating new TensorFlow objects inside the function (e.g., Variables, Tensors) unless necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a742e",
   "metadata": {},
   "source": [
    "11.\tWhen would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13441bc",
   "metadata": {},
   "source": [
    "You would need to create a dynamic Keras model when you have a variable-length input or output shape, such as when working with sequence data, where the length of the sequence can vary. \n",
    "\n",
    "To create a dynamic Keras model, you can use the Keras Functional API and use the `tf.keras.layers.Input` layer to define an input tensor with a variable-length dimension (set to `None`). This allows the model to accept inputs of different sizes.\n",
    "\n",
    "You would not want to make all your models dynamic because dynamic models cannot be easily converted to a static graph representation, which is required for deployment on certain platforms, such as mobile devices or embedded systems. Additionally, dynamic models may have higher memory usage and slower performance compared to static models. Therefore, it is recommended to use dynamic models only when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65181ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
